% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modeling_and_fitting.R
\name{modeling_and_fitting}
\alias{modeling_and_fitting}
\title{Create 5-layer Keras Model and Fitting Datasets}
\usage{
modeling_and_fitting(
  data_list,
  first_layer_unit,
  second_layer_drop_rate,
  third_layer_unit,
  fourth_layer_drop_rate,
  epochs = 30,
  batch_size = 16,
  validation_split = 0.2,
  test_split = NULL,
  first_layer_activation = "relu",
  third_layer_activation = "relu",
  fifth_layer_activation = "softmax",
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("accuracy"),
  model_file = tempfile(pattern = "keras_model", tmpdir = file.path(tempdir(),
    "sigminer.pred"), fileext = ".h5"),
  test_mode = FALSE
)
}
\arguments{
\item{data_list}{A \code{list} containing predictor and label matrix of training data and test data.
Please use \link{prepare_data} to generate this.}

\item{first_layer_unit}{Positive integer, dimensionality of the output space for the first layer.}

\item{second_layer_drop_rate}{Float between 0 and 1. Fraction of the input units to drop for the second layer.}

\item{third_layer_unit}{Positive integer, dimensionality of the output space for the third layer.}

\item{fourth_layer_drop_rate}{Float between 0 and 1. Fraction of the input units to drop for the fourth layer.}

\item{epochs}{Number of epochs to train the model, default is \code{30}.}

\item{batch_size}{Integer or NULL. Number of samples per gradient update. If unspecified, batch_size will default to \code{16}.}

\item{validation_split}{Float between 0 and 1. Fraction of the training data
to be used as validation data. The model will set apart this fraction of
the training data, will not train on it, and will evaluate the loss and any
model metrics on this data at the end of each epoch. The validation data
is selected from the last samples in the \code{x} and \code{y} data provided,
before shuffling.}

\item{test_split}{Float between 0 and 1. Fraction of the all data to be used as test data.
If not set, it will be auto-calculated from input data. This value is used for calculating
total accuracy.}

\item{first_layer_activation}{activation function for the first layer, default is "relu".}

\item{third_layer_activation}{activation function for the third layer, default is "relu".}

\item{fifth_layer_activation}{activation function for the fifth layer, default is "softmax".}

\item{loss}{Name of objective function or objective function. If the model
has multiple outputs, you can use a different loss on each output by
passing a dictionary or a list of objectives. The loss value that will be
minimized by the model will then be the sum of all individual losses.}

\item{optimizer}{Name of optimizer or optimizer instance.}

\item{metrics}{List of metrics to be evaluated by the model during training
and testing. Typically you will use \code{metrics='accuracy'}. To specify
different metrics for different outputs of a multi-output model, you could
also pass a named list such as \code{metrics=list(output_a = 'accuracy')}.}

\item{model_file}{file path to save the model file in \code{hdf5} format. Default use a temp file path,
the path will be stored in returned data. You can load the model with \code{\link[keras:load_model_hdf5]{keras::load_model_hdf5()}}.}

\item{test_mode}{Default is \code{FALSE}, if \code{TRUE}, print the input parameters from the user and exit.}
}
\value{
a \code{tibble}.
}
\description{
Create 5-layer Keras Model and Fitting Datasets
}
\examples{
load(system.file("extdata", "wang2020-input.RData",
  package = "sigminer.prediction", mustWork = TRUE
))
dat_list <- prepare_data(expo_all,
  col_to_vars = c(paste0("Sig", 1:5), paste0("AbsSig", 1:5)),
  col_to_label = "enrich_sig",
  label_names = paste0("Sig", 1:5)
)
res <- modeling_and_fitting(dat_list, 20, 0, 20, 0.1)
res$history[[1]] \%>\% plot()

## Load model and predict
model <- load_model_hdf5(res$model_file)

model \%>\% predict_classes(dat_list$x_train[1, , drop = FALSE])
model \%>\% predict_proba(dat_list$x_train[1, , drop = FALSE])
}
